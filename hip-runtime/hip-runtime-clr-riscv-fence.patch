diff --git a/hipamd/src/hip_graph_internal.cpp b/hipamd/src/hip_graph_internal.cpp
index 794293b7f..10e5b1de1 100644
--- a/hipamd/src/hip_graph_internal.cpp
+++ b/hipamd/src/hip_graph_internal.cpp
@@ -979,9 +979,17 @@ void GraphKernelArgManager::ReadBackOrFlush() {
       address dev_ptr =
           kernarg_graph_.back().kernarg_pool_addr_ + kernarg_graph_.back().kernarg_pool_size_;
       auto kSentinel = *reinterpret_cast<volatile unsigned char*>(dev_ptr - 1);
+#if defined(__x86_64__)
       _mm_sfence();
+#elif defined(__riscv)
+      asm volatile("fence rw, rw");
+#endif
       *(dev_ptr - 1) = kSentinel;
+#if defined(__x86_64__)
       _mm_mfence();
+#elif defined(__riscv)
+      asm volatile("fence rw, rw");
+#endif
       kSentinel = *reinterpret_cast<volatile unsigned char*>(dev_ptr - 1);
     }
   }
diff --git a/rocclr/device/rocm/rocvirtual.cpp b/rocclr/device/rocm/rocvirtual.cpp
index 722450a14..a58ba908c 100644
--- a/rocclr/device/rocm/rocvirtual.cpp
+++ b/rocclr/device/rocm/rocvirtual.cpp
@@ -3282,9 +3282,17 @@ bool VirtualGPU::submitKernelInternal(const amd::NDRangeContainer& sizes,
           auto kSentinel = *reinterpret_cast<volatile int*>(dev().info().hdpMemFlushCntl);
         } else if (kernArgImpl == KernelArgImpl::DeviceKernelArgsReadback &&
                    argSize != 0) {
+#if defined(__x86_64__)
           _mm_sfence();
+#elif defined(__riscv)
+          asm volatile("fence rw, rw");
+#endif
           *(argBuffer + argSize - 1) = *(parameters + argSize - 1);
+#if defined(__x86_64__)
           _mm_mfence();
+#elif defined(__riscv)
+          asm volatile("fence rw, rw");
+#endif
           auto kSentinel = *reinterpret_cast<volatile unsigned char*>(
               argBuffer + argSize - 1);
         }

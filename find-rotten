#!/usr/bin/env python

import concurrent.futures
import logging
import os
import re
import shutil
import tempfile

import pyalpm
from pyalpm import Handle, DB
import sh
from git import Repo
from github import Github

logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

ENV = os.environ.copy()
ENV["LANG"] = "C"

RE_HUNK_FAILED = re.compile(r"^\d+ out of \d+ hunks? FAILED", re.MULTILINE)
RE_REVERSED = re.compile(r"^Reversed \(or previously applied\) patch detected")
RE_PR_RM_PACKAGE = re.compile(r"^(rm|rmv)(pkg|patch): ([^ ]+)")

SOURCE_REPO = 'https://gitlab.archlinux.org/archlinux/packaging/packages/{package}'
ARCHLINUX_REPO = 'https://geo.mirror.pkgbuild.com/{repo}/os/x86_64'

repo = Repo()
g = Github(ENV["GITHUB_TOKEN"])
gh_repo = g.get_repo(ENV["GITHUB_REPO"])


# get packages list from repo
def get_all_packages() -> dict[str, str]:
    result = {}
    with tempfile.TemporaryDirectory() as tempdir:
        handle = Handle('/', tempdir)
        for db_name in ['core', 'extra']:
            db: DB = handle.register_syncdb(db_name, pyalpm.SIG_DATABASE_OPTIONAL)
            db.servers = [ARCHLINUX_REPO.format(repo=db.name)]
            db.update(False)
            result.update({pkg.base: pkg.version for pkg in db.pkgcache})
    return result


all_packages = get_all_packages()
if not os.path.exists(os.path.expanduser('~/.cache/packages')):
    os.makedirs(os.path.expanduser('~/.cache/packages'))


def is_rotten(package):
    version = all_packages[package].replace(':', '-')
    if os.path.exists(f"~/.cache/packages/{package}"):
        if version not in sh.git.tag(_tty_out=False, _cwd=f"~/.cache/packages/{package}").split():
            sh.git.pull(_cwd=f"~/.cache/packages/{package}")
    else:
        sh.git.clone(SOURCE_REPO.format(package=package), _cwd="~/.cache/packages")

    with tempfile.TemporaryDirectory() as tempdir:
        sh.git.clone(f"~/.cache/packages/{package}", _cwd=tempdir, _env=ENV)
        sh.git.checkout(version, _cwd=f"{tempdir}/{package}", _env=ENV)

        try:
            shutil.copytree(package, f"{tempdir}/{package}", dirs_exist_ok=True)
            try:
                sh.patch("-sNp0", "-i", "riscv64.patch", _cwd=f"{tempdir}/{package}", _env=ENV)
            except sh.ErrorReturnCode as e:
                if e.exit_code == 1:
                    stdout = e.stdout.decode('ascii')
                    if RE_HUNK_FAILED.search(stdout) or RE_REVERSED.search(stdout):
                        return True
                raise e
        except FileNotFoundError as e:
            return True

    return False


def done_callback(futures, future):
    package_name = futures[future]
    exc = future.exception()
    if exc:
        logger.exception(f"unexpected error occurred when checking {package_name}",
                         exc_info=exc)
        return


# call this after making changes to repo index
def commit_rm_package_push_pr(package):
    repo.index.commit(f"rmvpatch: {package}")
    branch_name = repo.active_branch.name
    repo.git.push("origin", branch_name)
    gh_repo.create_pull(title=f"rmvpatch: {package}",
                        body="This package has been removed in Arch.",
                        base="master",
                        head=branch_name)
    logger.info(f"created rmvpatch PR for {package}")


def main():
    packages = set()
    for dirent in os.scandir():
        if not dirent.is_dir() or dirent.name.startswith(".") or "bootstrap" in dirent.name:
            continue
        if not os.path.exists(os.path.join(dirent.name, "riscv64.patch")):
            continue
        packages.add(dirent.name)

    # all_packages = set(sh.asp("list-all").stdout.decode("ascii").strip().split())

    pulls = gh_repo.get_pulls(state='open', sort='created', base='master')
    rm_package_in_pr = set()
    for pr in pulls:
        if match := RE_PR_RM_PACKAGE.match(pr.title):
            rm_package_in_pr.add(match.group(3))

    if ghosts := packages - set(all_packages):
        logger.warning("nonexistent packages: \n{}\n".format("\n".join(sorted(ghosts))))

        # for ghost in ghosts:
        #     if ghost in rm_package_in_pr:
        #         continue
        #     current_branch = repo.active_branch
        #     new_branch = repo.create_head(f"actions-rm-{ghost}")
        #     new_branch.checkout()
        #     repo.index.remove(ghost, working_tree=True, r=True)
        #     commit_rm_package_push_pr(ghost)
        #     current_branch.checkout()

    with open('qemu-user-blacklist.txt') as qemu_user_blacklist:
        qemu_user_blacklist_packages = set(qemu_user_blacklist.read().split())
        if qemu_user_blacklist_ghosts := qemu_user_blacklist_packages - set(all_packages):
            logger.warning("nonexistent packages in qemu-user-blacklist.txt: \n{}\n".format(
                "\n".join(sorted(qemu_user_blacklist_ghosts))))

    packages = packages & set(all_packages)

    futures = {}
    with concurrent.futures.ThreadPoolExecutor() as pool:
        for package in packages:
            fut = pool.submit(is_rotten, package)
            futures[fut] = package
            fut.add_done_callback(lambda f: done_callback(futures, f))

        concurrent.futures.wait(futures.keys())

    rotten = []
    for future, package_name in futures.items():
        if not future.exception() and future.result():
            rotten.append(package_name)

    print("\n".join(sorted(rotten)))

    if rotten:
        logger.warning(f"found {len(rotten)} rotten patches")


if __name__ == "__main__":
    main()
